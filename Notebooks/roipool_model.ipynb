{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d6e00d0-3bd7-4169-b8ba-4bda12d52af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.style as style\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import json\n",
    "from scipy.stats import spearmanr\n",
    "from datetime import datetime\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.calibration import calibration_curve\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from keras import backend as K\n",
    "import sys\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d09eea2-7caa-4205-9a06-60b9c38f1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data_csv_files/train_mos.csv')\n",
    "df_val = pd.read_csv('data_csv_files/val_mos.csv')\n",
    "df_test = pd.read_csv('data_csv_files/test_mos.csv')\n",
    "\n",
    "X_train = df_train['image'].tolist()\n",
    "X_val = df_val['image'].tolist()\n",
    "X_test = df_test['image'].tolist()\n",
    "\n",
    "train_y_qual = df_train['qual_mos'].tolist()\n",
    "val_y_qual = df_val['qual_mos'].tolist()\n",
    "test_y_qual = df_test['qual_mos'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b30f3116-cb6d-423c-8e8e-a7625c71cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ['../../vizwiz/train/'+f+'.jpg' for f in X_train]\n",
    "X_val = ['../../vizwiz/val/'+f+'.jpg' for f in X_val]\n",
    "X_test = ['../../vizwiz/test/'+f+'.jpg' for f in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f6a00594-42e6-4a3e-a3ac-ba511ac8e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 448 # Specify height and width of image to match the input format of the model\n",
    "CHANNELS = 3 # Keep RGB color channels to match the input format of the model\n",
    "\n",
    "BATCH_SIZE = 32 # Big enough to measure an F1-score\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically\n",
    "SHUFFLE_BUFFER_SIZE = 64 # Shuffle the training data by a chunck of 1024 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fd294a83-2e40-4195-a0b6-b598befe1086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_function(filename, label):\n",
    "    # Read an image from a file\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    # Decode it into a dense vector\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n",
    "    # Resize it to fixed shape\n",
    "    image_resized = tf.image.resize(image_decoded, [IMG_SIZE, IMG_SIZE])\n",
    "    # Normalize it from [0, 255] to [0.0, 1.0]\n",
    "    image_normalized = image_resized / 255.0\n",
    "    return image_normalized, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "58e093f0-2792-4186-830d-165c1d657da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(filenames, rois, label_1, label_2, is_training):\n",
    "    \"\"\"Load and parse dataset.\n",
    "    Args:\n",
    "        filenames: list of image paths\n",
    "        labels: numpy array of shape (BATCH_SIZE, N_LABELS)\n",
    "        is_training: boolean to indicate training mode\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a first dataset of file paths and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(({'input_layer':filenames,'input_rois':rois}, {'output_1':label_1,'output_2':label_2}))\n",
    "    # Parse and preprocess observations in parallel\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    if is_training == True:\n",
    "        # This is a small dataset, only load it once, and keep it in memory.\n",
    "        dataset = dataset.cache()\n",
    "        # Shuffle the data each buffer size\n",
    "        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
    "\n",
    "    # Batch the data for multiple steps\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # Fetch batches in the background while the model is training.\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73e32a22-2ccb-4f8a-9cc1-fd8a9232bde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_dataset(X_train, train_y_qual, is_training=True)\n",
    "val_ds = create_dataset(X_val, val_y_qual, is_training=False)\n",
    "test_ds = create_dataset(X_test, test_y_qual, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "047cf0d7-e603-4460-a606-8d5ed1723925",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNet50V2(input_shape=(IMG_SIZE,IMG_SIZE,CHANNELS),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dc348e0-b0ed-46d7-9606-d31738eb70b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def srcc(y_true, y_pred):\n",
    "     return ( tf.py_function(spearmanr, [tf.cast(y_pred, tf.float32),\n",
    "                       tf.cast(y_true, tf.float32)], Tout = tf.float32) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a3132a1-3db5-465e-a2ba-dbc6a180ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-5 # Keep it small when transfer learning\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c5e8a04a-9c64-4702-a4da-aeb7453d2133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Layer\n",
    "import keras.backend as K\n",
    "\n",
    "if K.backend() == 'tensorflow':\n",
    "    import tensorflow as tf\n",
    "\n",
    "class RoiPoolingConv(Layer):\n",
    "    def __init__(self, pool_size, num_rois, **kwargs):\n",
    "\n",
    "\n",
    "        self.pool_size = 2\n",
    "        self.num_rois = 1\n",
    "\n",
    "        super(RoiPoolingConv, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.nb_channels = input_shape[0][3]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return None, self.num_rois, self.pool_size, self.pool_size, self.nb_channels\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        assert(len(x) == 2)\n",
    "\n",
    "        img = x[0]\n",
    "        rois = x[1]\n",
    "\n",
    "        input_shape = K.shape(img)\n",
    "\n",
    "\n",
    "        #for roi_idx in range(self.num_rois):\n",
    "\n",
    "        x = rois[0, 0]\n",
    "        y = rois[0, 1]\n",
    "        w = rois[0, 2]\n",
    "        h = rois[0, 3]\n",
    "\n",
    "        num_pool_regions = self.pool_size\n",
    "\n",
    "        x = K.cast(x, 'int32')\n",
    "        y = K.cast(y, 'int32')\n",
    "        w = K.cast(w, 'int32')\n",
    "        h = K.cast(h, 'int32')\n",
    "\n",
    "        rs = tf.image.resize(img[:, y:y+h, x:x+w, :], (self.pool_size, self.pool_size))\n",
    "\n",
    "        #final_output = K.reshape(rs, (1, self.pool_size, self.pool_size, self.nb_channels))\n",
    "        final_output = rs\n",
    "        return final_output\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'pool_size': self.pool_size,\n",
    "                  'num_rois': self.num_rois}\n",
    "        base_config = super(RoiPoolingConv, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "141b6874-668a-4751-9cc8-3b9e76cdfb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\n",
    "    #input_shape = (1,7,7,512)\n",
    "\n",
    "    pooling_regions = 2\n",
    "    \n",
    "    input_rois = layers.Input(shape=(4), name='input_rois')\n",
    "    input_layer = layers.Input(shape=(IMG_SIZE,IMG_SIZE,CHANNELS), name='input_layer')\n",
    "    \n",
    "    # out_roi_pool.shape = (1, num_rois, channels, pool_size, pool_size)\n",
    "    # num_rois (4) 7x7 roi pooling\n",
    "    base_layers = base_model(input_layer, training=False)\n",
    "    out_roi_pool = RoiPoolingConv(pooling_regions, 1)([base_layers, input_rois])\n",
    "\n",
    "    # Flatten the convlutional layer and connected to 2 FC and 2 dropout\n",
    "    x = layers.TimeDistributed(layers.Flatten(name='flatten'))(out_roi_pool)\n",
    "    x = layers.TimeDistributed(layers.Dense(512, activation='relu', name='fc1'))(x)\n",
    "    x = layers.TimeDistributed(layers.Dropout(0.2))(x)\n",
    "    x = layers.TimeDistributed(layers.Dense(32, activation='relu', name='fc2'))(x)\n",
    "    x = layers.TimeDistributed(layers.Dropout(0.2))(x)\n",
    "    output_1 = layers.Dense(7, name='output_1')(x)\n",
    "\n",
    "#     x = layers.Flatten(name='flatten')(out_roi_pool)\n",
    "#     x = layers.Dense(512, activation='relu', name='fc1')(x)\n",
    "#     x = layers.Dropout(0.2)(x)\n",
    "#     x = layers.Dense(32, activation='relu', name='fc2')(x)\n",
    "#     x = layers.Dropout(0.2)(x)\n",
    "#     output_1 = layers.Dense(1, name='output_1')(x)\n",
    "#     output_2 = layers.Dense(1, name='output_2')(x)\n",
    "\n",
    "    model = models.Model(inputs=[input_layer, input_rois], outputs=[output_1])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5dd7a18c-eec2-4234-a685-4c064087aff2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-123-cd807df3d41c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-123-cd807df3d41c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    a = [[1,2];[3,2]]\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a = [[1,2];[3,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f48c27c8-273d-4754-be3f-fc9412f8226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "863e45d0-2a32-4716-86da-fb1c77e7cd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_rois (InputLayer)         [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_107 (S ()                   0           input_rois[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_109 (S ()                   0           input_rois[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_106 (S ()                   0           input_rois[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_108 (S ()                   0           input_rois[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_layer (InputLayer)        [(None, 448, 448, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_65 (TFOpLambda)         ()                   0           tf.__operators__.getitem_107[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_67 (TFOpLambda)         ()                   0           tf.__operators__.getitem_109[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_64 (TFOpLambda)         ()                   0           tf.__operators__.getitem_106[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_66 (TFOpLambda)         ()                   0           tf.__operators__.getitem_108[0][0\n",
      "__________________________________________________________________________________________________\n",
      "resnet50v2 (Functional)         (None, 14, 14, 2048) 23564800    input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_32 (TFOpLa ()                   0           tf.cast_65[0][0]                 \n",
      "                                                                 tf.cast_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_33 (TFOpLa ()                   0           tf.cast_64[0][0]                 \n",
      "                                                                 tf.cast_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_110 (S (None, None, None, 2 0           resnet50v2[3][0]                 \n",
      "                                                                 tf.cast_65[0][0]                 \n",
      "                                                                 tf.__operators__.add_32[0][0]    \n",
      "                                                                 tf.cast_64[0][0]                 \n",
      "                                                                 tf.__operators__.add_33[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.image.resize_14 (TFOpLambda) (None, 2, 2, 2048)   0           tf.__operators__.getitem_110[0][0\n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_21 (TimeDistri (None, 2, 4096)      0           tf.image.resize_14[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_22 (TimeDistri (None, 2, 512)       2097664     time_distributed_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_23 (TimeDistri (None, 2, 512)       0           time_distributed_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_24 (TimeDistri (None, 2, 32)        16416       time_distributed_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_25 (TimeDistri (None, 2, 32)        0           time_distributed_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "output_1 (Dense)                (None, 2, 7)         231         time_distributed_25[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 25,679,111\n",
      "Trainable params: 2,114,311\n",
      "Non-trainable params: 23,564,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a3dbb1fd-6e3c-4bab-a08a-4fccb6cb7a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_rois (InputLayer)         [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_92 (Sl ()                   0           input_rois[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_94 (Sl ()                   0           input_rois[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_91 (Sl ()                   0           input_rois[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_93 (Sl ()                   0           input_rois[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_layer (InputLayer)        [(None, 448, 448, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_53 (TFOpLambda)         ()                   0           tf.__operators__.getitem_92[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_55 (TFOpLambda)         ()                   0           tf.__operators__.getitem_94[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_52 (TFOpLambda)         ()                   0           tf.__operators__.getitem_91[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.cast_54 (TFOpLambda)         ()                   0           tf.__operators__.getitem_93[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "resnet50v2 (Functional)         (None, 14, 14, 2048) 23564800    input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_26 (TFOpLa ()                   0           tf.cast_53[0][0]                 \n",
      "                                                                 tf.cast_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_27 (TFOpLa ()                   0           tf.cast_52[0][0]                 \n",
      "                                                                 tf.cast_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_95 (Sl (None, None, None, 2 0           resnet50v2[0][0]                 \n",
      "                                                                 tf.cast_53[0][0]                 \n",
      "                                                                 tf.__operators__.add_26[0][0]    \n",
      "                                                                 tf.cast_52[0][0]                 \n",
      "                                                                 tf.__operators__.add_27[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.image.resize_11 (TFOpLambda) (None, 2, 2, 2048)   0           tf.__operators__.getitem_95[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 8192)         0           tf.image.resize_11[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 512)          4194816     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 512)          0           fc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc2 (Dense)                     (None, 32)           16416       dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 32)           0           fc2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "output_1 (Dense)                (None, 1)            33          dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output_2 (Dense)                (None, 1)            33          dropout_23[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 27,776,098\n",
      "Trainable params: 4,211,298\n",
      "Non-trainable params: 23,564,800\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " input image must be of non-zero size\n\t [[node model_10/tf.image.resize_11/resize/ResizeBilinear (defined at <ipython-input-114-cc202340c714>:331) ]] [Op:__inference_train_function_28770]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-cc202340c714>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m history = model.fit(train_ds,\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/work/notebooks/model/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/work/notebooks/model/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/work/notebooks/model/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/work/notebooks/model/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/work/notebooks/model/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/Desktop/work/notebooks/model/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/work/notebooks/model/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  input image must be of non-zero size\n\t [[node model_10/tf.image.resize_11/resize/ResizeBilinear (defined at <ipython-input-114-cc202340c714>:331) ]] [Op:__inference_train_function_28770]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "############### XceptionNet\n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.style as style\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import json\n",
    "from scipy.stats import spearmanr\n",
    "from datetime import datetime\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.calibration import calibration_curve\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from keras import backend as K\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "import sys\n",
    "import pickle\n",
    "import ast\n",
    "\n",
    "model_name = 'test_roipool'\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "# with open('quality.json') as json_file:\n",
    "#     data = json.load(json_file)\n",
    "\n",
    "\n",
    "# X_train = data['train']['image']\n",
    "# X_val = data['val']['image']\n",
    "\n",
    "df_Tr = pd.read_csv('master_data_train.csv')\n",
    "df_Va = pd.read_csv('master_data_val.csv')\n",
    "df_Ts = pd.read_csv('master_data_test.csv')\n",
    "\n",
    "if type == 'rand':\n",
    "    df_train = df_Tr.loc[df_Tr['type'] == 'rand']\n",
    "    df_val = df_Va.loc[df_Va['type'] == 'rand']\n",
    "    df_test = df_Ts.loc[df_Ts['type'] == 'rand']\n",
    "elif type == 'sal':\n",
    "    df_train = df_Tr.loc[df_Tr['type'] == 'sal']\n",
    "    df_val = df_Va.loc[df_Va['type'] == 'sal']\n",
    "    df_test = df_Ts.loc[df_Ts['type'] == 'sal']\n",
    "else:\n",
    "    df_train = df_Tr\n",
    "    df_val = df_Va\n",
    "    df_test = df_Ts\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val= df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "X_train = df_train['image'].tolist()\n",
    "X_val = df_val['image'].tolist()\n",
    "X_test = df_test['image'].tolist()\n",
    "\n",
    "train_img_qual = df_train['img_qual'].tolist()\n",
    "val_img_qual = df_val['img_qual'].tolist()\n",
    "test_img_qual = df_test['img_qual'].tolist()\n",
    "\n",
    "train_patch_qual = df_train['patch_qual'].tolist()\n",
    "val_patch_qual = df_val['patch_qual'].tolist()\n",
    "test_patch_qual = df_test['patch_qual'].tolist()\n",
    "\n",
    "X_train = ['../../vizwiz/train/'+f+'.jpg' for f in X_train]\n",
    "X_val = ['../../vizwiz/val/'+f+'.jpg' for f in X_val]\n",
    "X_test = ['../../vizwiz/test/'+f+'.jpg' for f in X_test]\n",
    "\n",
    "df_train['rescaled_448_coord'] = df_train['rescaled_448_coord'].apply(ast.literal_eval)\n",
    "X_roi_train = []\n",
    "for i in range(len(X_train)):\n",
    "  C = df_train['rescaled_448_coord'][i]\n",
    "  y = [int(c) for c in C]\n",
    "  X_roi_train.append(y)\n",
    "\n",
    "df_val['rescaled_448_coord'] = df_val['rescaled_448_coord'].apply(ast.literal_eval)\n",
    "X_roi_val = []\n",
    "for i in range(len(X_val)):\n",
    "  C = df_val['rescaled_448_coord'][i]\n",
    "  y = [int(c) for c in C]\n",
    "  X_roi_val.append(y)\n",
    "\n",
    "df_test['rescaled_448_coord'] = df_test['rescaled_448_coord'].apply(ast.literal_eval)\n",
    "X_roi_test = []\n",
    "for i in range(len(X_test)):\n",
    "  C = df_test['rescaled_448_coord'][i]\n",
    "  y = [int(c) for c in C]\n",
    "  X_roi_test.append(y)\n",
    "\n",
    "\n",
    "IMG_SIZE = 448 # Specify height and width of image to match the input format of the model\n",
    "CHANNELS = 3 # Keep RGB color channels to match the input format of the model\n",
    "\n",
    "def parse_function(input, label):\n",
    "    # Read an image from a file\n",
    "    filename = input['input_layer']\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    # Decode it into a dense vector\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n",
    "    # Resize it to fixed shape\n",
    "    image_resized = tf.image.resize(image_decoded, [IMG_SIZE, IMG_SIZE])\n",
    "    # Normalize it from [0, 255] to [0.0, 1.0]\n",
    "    image_normalized = image_resized / 255.0\n",
    "\n",
    "    input['input_layer'] = image_normalized\n",
    "    return input, label\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64 # Big enough to measure an F1-score\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically\n",
    "SHUFFLE_BUFFER_SIZE = 128 # Shuffle the training data by a chunck of 1024 observations\n",
    "\n",
    "def create_dataset(filenames, rois, label_1, label_2, is_training):\n",
    "    \"\"\"Load and parse dataset.\n",
    "    Args:\n",
    "        filenames: list of image paths\n",
    "        labels: numpy array of shape (BATCH_SIZE, N_LABELS)\n",
    "        is_training: boolean to indicate training mode\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a first dataset of file paths and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(({'input_layer':filenames,'input_rois':rois}, {'output_1':label_1,'output_2':label_2}))\n",
    "\n",
    "    # Parse and preprocess observations in parallel\n",
    "    dataset = dataset.map(parse_function, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    if is_training == True:\n",
    "        # This is a small dataset, only load it once, and keep it in memory.\n",
    "        dataset = dataset.take(SHUFFLE_BUFFER_SIZE).cache()\n",
    "        # Shuffle the data each buffer size\n",
    "        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
    "\n",
    "    # Batch the data for multiple steps\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    # Fetch batches in the background while the model is training.\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "train_ds = create_dataset(X_train, X_roi_train, train_img_qual, train_patch_qual, is_training=True)\n",
    "val_ds = create_dataset(X_val, X_roi_val, val_img_qual, val_patch_qual, is_training=False)\n",
    "test_ds = create_dataset(X_test, X_roi_test, test_img_qual, test_patch_qual, is_training=False)\n",
    "\n",
    "# print(X_val)\n",
    "\n",
    "# feature_extractor_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\"\n",
    "# feature_extractor_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
    "# feature_extractor_layer = hub.KerasLayer(feature_extractor_url, input_shape=(IMG_SIZE,IMG_SIZE,CHANNELS))\n",
    "\n",
    "base_model = tf.keras.applications.ResNet50V2(input_shape=(IMG_SIZE,IMG_SIZE,CHANNELS),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "# # Fine-tune from this layer onwards\n",
    "# fine_tune_at = 125\n",
    "#\n",
    "# # Freeze all the layers before the `fine_tune_at` layer\n",
    "# for layer in base_model.layers[:fine_tune_at]:\n",
    "#   layer.trainable =  False\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "# feature_extractor_layer.trainable = False\n",
    "\n",
    "@tf.function\n",
    "def macro_f1(y, y_hat, thresh=0.5):\n",
    "    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n",
    "\n",
    "    Args:\n",
    "        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n",
    "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
    "        thresh: probability value above which we predict positive\n",
    "\n",
    "    Returns:\n",
    "        macro_f1 (scalar Tensor): value of macro F1 for the batch\n",
    "    \"\"\"\n",
    "    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n",
    "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
    "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
    "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
    "    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "    macro_f1 = tf.reduce_mean(f1)\n",
    "    return macro_f1\n",
    "\n",
    "def pearson_r(y_true, y_pred):\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    mx = K.mean(x, axis=0)\n",
    "    my = K.mean(y, axis=0)\n",
    "    xm, ym = x - mx, y - my\n",
    "    r_num = K.sum(xm * ym)\n",
    "    x_square_sum = K.sum(xm * xm)\n",
    "    y_square_sum = K.sum(ym * ym)\n",
    "    r_den = K.sqrt(x_square_sum * y_square_sum)\n",
    "    r = r_num / r_den\n",
    "    return K.mean(r)\n",
    "\n",
    "def srcc(y_true, y_pred):\n",
    "     return ( tf.py_function(spearmanr, [tf.cast(y_pred, tf.float32),\n",
    "                       tf.cast(y_true, tf.float32)], Tout = tf.float32) )\n",
    "\n",
    "LR = 1e-5 # Keep it small when transfer learning\n",
    "EPOCHS = 10\n",
    "\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "import keras.backend as K\n",
    "\n",
    "if K.backend() == 'tensorflow':\n",
    "    import tensorflow as tf\n",
    "\n",
    "class RoiPoolingConv(Layer):\n",
    "    def __init__(self, pool_size, num_rois, **kwargs):\n",
    "\n",
    "\n",
    "        self.pool_size = 2\n",
    "        self.num_rois = 1\n",
    "\n",
    "        super(RoiPoolingConv, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.nb_channels = input_shape[0][3]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return None, self.num_rois, self.pool_size, self.pool_size, self.nb_channels\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        assert(len(x) == 2)\n",
    "\n",
    "        img = x[0]\n",
    "        rois = x[1]\n",
    "\n",
    "        input_shape = K.shape(img)\n",
    "\n",
    "\n",
    "        #for roi_idx in range(self.num_rois):\n",
    "\n",
    "        x = rois[0, 0]\n",
    "        y = rois[0, 1]\n",
    "        w = rois[0, 2]\n",
    "        h = rois[0, 3]\n",
    "\n",
    "        num_pool_regions = self.pool_size\n",
    "\n",
    "        x = K.cast(x, 'int32')\n",
    "        y = K.cast(y, 'int32')\n",
    "        w = K.cast(w, 'int32')\n",
    "        h = K.cast(h, 'int32')\n",
    "\n",
    "        rs = tf.image.resize(img[:, y:y+h, x:x+w, :], (self.pool_size, self.pool_size))\n",
    "\n",
    "        #final_output = K.reshape(rs, (1, self.pool_size, self.pool_size, self.nb_channels))\n",
    "        final_output = rs\n",
    "        return final_output\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'pool_size': self.pool_size,\n",
    "                  'num_rois': self.num_rois}\n",
    "        base_config = super(RoiPoolingConv, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "\n",
    "def build_model():\n",
    "\n",
    "    #input_shape = (1,7,7,512)\n",
    "\n",
    "    pooling_regions = 2\n",
    "\n",
    "    input_rois = layers.Input(shape=(4), name='input_rois')\n",
    "    input_layer = layers.Input(shape=(IMG_SIZE,IMG_SIZE,CHANNELS), name='input_layer')\n",
    "\n",
    "    # out_roi_pool.shape = (1, num_rois, channels, pool_size, pool_size)\n",
    "    # num_rois (4) 7x7 roi pooling\n",
    "    base_layers = base_model(input_layer, training=False)\n",
    "    out_roi_pool = RoiPoolingConv(pooling_regions, 1)([base_layers, input_rois])\n",
    "\n",
    "    # Flatten the convlutional layer and connected to 2 FC and 2 dropout\n",
    "#     x = layers.TimeDistributed(layers.Flatten(name='flatten'))(out_roi_pool)\n",
    "#     x = layers.TimeDistributed(layers.Dense(512, activation='relu', name='fc1'))(x)\n",
    "#     x = layers.TimeDistributed(layers.Dropout(0.2))(x)\n",
    "#     x = layers.TimeDistributed(layers.Dense(32, activation='relu', name='fc2'))(x)\n",
    "#     x = layers.TimeDistributed(layers.Dropout(0.2))(x)\n",
    "\n",
    "    x = layers.Flatten(name='flatten')(out_roi_pool)\n",
    "    x = layers.Dense(512, activation='relu', name='fc1')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(32, activation='relu', name='fc2')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output_1 = layers.Dense(1, name='output_1')(x)\n",
    "    output_2 = layers.Dense(1, name='output_2')(x)\n",
    "\n",
    "    model = models.Model(inputs=[input_layer, input_rois], outputs=[output_1, output_2])\n",
    "\n",
    "    return model\n",
    "\n",
    "model=build_model()\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss={'output_1': 'mse', 'output_2': 'mse'},\n",
    " metrics={'output_1':srcc,\n",
    "          'output_2':srcc})\n",
    "\n",
    "lr = float(0.001)\n",
    "def scheduler(epoch):\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr*tf.math.exp(-0.1)\n",
    "\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "checkpoint_filepath = \"./models/\"+model_name+'_checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "start = time.time()\n",
    "history = model.fit(train_ds,\n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=[callback,model_checkpoint_callback],\n",
    "                    validation_data=val_ds)\n",
    "print('\\nTraining took {}'.format(time.time()-start))\n",
    "\n",
    "export_path = \"./models/\"+model_name+\".h5\"\n",
    "model.save(export_path)\n",
    "print(\"Model was exported in this path: '{}'\".format(export_path))\n",
    "\n",
    "# Get the dictionary containing each metric and the loss for each epoch\n",
    "history_dict = history.history\n",
    "history_path = 'fit_history_'+model_name+'.pkl'\n",
    "with open(history_path, 'wb') as f:\n",
    "    pickle.dump(history_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "y_pred = model.predict(test_ds)\n",
    "with open('test_img_qual_'+model_name+'.npy', 'wb') as f:\n",
    "    np.save(f, y_pred[0])\n",
    "with open('test_patch_qual_'+model_name+'.npy', 'wb') as f:\n",
    "    np.save(f, y_pred[1])\n",
    "# qual_pred = y_pred[1]\n",
    "img_qual_pred = []\n",
    "for i in range(len(y_pred[0])):\n",
    "    img_qual_pred.append(y_pred[0][i][0])\n",
    "\n",
    "patch_qual_pred = []\n",
    "for i in range(len(y_pred[1])):\n",
    "    img_qual_pred.append(y_pred[1][i][0])\n",
    "\n",
    "# print(val_y_qual)\n",
    "# print(y_qual_pred)\n",
    "\n",
    "print('Image SRCC: ', spearmanr(test_img_qual, img_qual_pred))\n",
    "print('Image LCC: ', pearsonr(test_img_qual, img_qual_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d640013f-e3e5-4c3f-aecb-01416e9ee641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model",
   "language": "python",
   "name": "model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
